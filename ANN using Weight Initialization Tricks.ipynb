{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290b0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88436eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_MOdelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f09880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a142b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting independent columns from third to thirteenth\n",
    "X = df.iloc[:,3:13]\n",
    "\n",
    "## Extracting dependent column Exited\n",
    "y = df.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf3d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies varible \n",
    "geography = pd.get_dummies(X['Geography'],drop_first=True)\n",
    "\n",
    "gender = pd.get_dummies(X['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001f9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now concat the columns in one dataset\n",
    "X = pd.concat([X,geography,gender],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "111df164",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AFter concat we have to remove these columns\n",
    "X = X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ab27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NO splitting my data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee73287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11)\n",
      "(2000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1ffd3",
   "metadata": {},
   "source": [
    "### Now some preprocessing\n",
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bee2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e613c0",
   "metadata": {},
   "source": [
    "# Let's Create ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f02c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import LeakyRelu,PRelu,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f2882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb4259",
   "metadata": {},
   "source": [
    "## Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2aae3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initilization technique\n",
    "# 1. he_normal\n",
    "# 2. he_uniform\n",
    "\n",
    "classifier.add(Dense(units=10, kernel_initializer = 'he_normal', activation='relu',input_dim=11))\n",
    "classifier.add(Dropout(0.3))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=20, kernel_initializer = 'he_normal', activation='relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(units=20, kernel_initializer = 'he_normal', activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer = 'glorot_uniform', activation='sigmoid'))\n",
    "\n",
    "# Complete the ANN\n",
    "classifier.compile(optimizer='adam', loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b88668e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 9s 6ms/step - loss: 0.5095 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5076 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5088 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 5s 9ms/step - loss: 0.5067 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5066 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5073 - val_accuracy: 0.7955\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 5s 9ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5089 - val_accuracy: 0.7955\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 5s 8ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5080 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 4s 8ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5072 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 4s 8ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 4s 8ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5073 - val_accuracy: 0.7955\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5082 - val_accuracy: 0.7955\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5068 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 2s 4ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 2s 4ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5073 - val_accuracy: 0.7955\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5075 - val_accuracy: 0.7955\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5072 - val_accuracy: 0.7955\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5079 - val_accuracy: 0.7955\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5082 - val_accuracy: 0.7955\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5079 - val_accuracy: 0.7955\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5076 - val_accuracy: 0.7955\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 2s 4ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5075 - val_accuracy: 0.7955\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5087 - val_accuracy: 0.7955\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5083 - val_accuracy: 0.7955\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5074 - val_accuracy: 0.7955\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 2s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 2s 5ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 2s 5ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5080 - val_accuracy: 0.7955\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5073 - val_accuracy: 0.7955\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 4s 7ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7955\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5073 - val_accuracy: 0.7955\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 2s 5ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5075 - val_accuracy: 0.7955\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 3s 5ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 3s 6ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the training set\n",
    "model_history = classifier.fit(X_train,y_train, validation_split=0.33,batch_size = 10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae400f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6b89de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "005f2b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c121a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b9d1d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred,y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
